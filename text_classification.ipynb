{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bsoup\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eachFile(filepath):\n",
    "    \"\"\"\n",
    "    get all the files in the dir\n",
    "    \"\"\"\n",
    "    pathDir =  os.listdir(filepath)\n",
    "    files = []\n",
    "    for allDir in pathDir:\n",
    "        child = os.path.join('%s%s' % (filepath, allDir))\n",
    "        files.append(child)\n",
    "    return files\n",
    "\n",
    "def get_text(path):\n",
    "    \"\"\"\n",
    "    get the text value in the file\n",
    "    \"\"\"\n",
    "    values = []\n",
    "    text = open(path, 'r')\n",
    "    for line in text:\n",
    "        values.append(line)\n",
    "    return ' '.join(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = eachFile('./Desktop/sentiment/movie/')\n",
    "movie_files = []\n",
    "for file in files:\n",
    "    if not file.find('.html') == -1:\n",
    "        movie_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = bsoup(get_text(movie_files[0]))\n",
    "import nltk\n",
    "movie_text = []\n",
    "for file in movie_files:\n",
    "    htmlfile = open(file, 'r',encoding='ISO-8859-1')\n",
    "    try:\n",
    "        htmlpage = htmlfile.read()\n",
    "    except:\n",
    "        print(file)\n",
    "    soup = bsoup(htmlpage, \"html.parser\")\n",
    "    if (soup.find('p') is None):\n",
    "        movie_text.append('')\n",
    "    else:\n",
    "        sent = soup.find('p').string\n",
    "#         tokens=nltk.word_tokenize(str(sent))\n",
    "        movie_text.append(str(sent))\n",
    "#print(movie_text[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "predict_data = pd.DataFrame(columns = ['file_name' , 'content'])\n",
    "predict_data['file_name'] = movie_files\n",
    "predict_data['content'] = movie_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "LancasterStem=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training data\n",
    "files = eachFile('./Desktop/sentiment/review_polarity/txt_sentoken/neg/')\n",
    "neg_files = []\n",
    "for file in files:\n",
    "    if not file.find('.txt') == -1:\n",
    "        neg_files.append(file)\n",
    "\n",
    "files = eachFile('./Desktop/sentiment/review_polarity/txt_sentoken/pos/')\n",
    "pos_files = []\n",
    "for file in files:\n",
    "    if not file.find('.txt') == -1:\n",
    "        pos_files.append(file)\n",
    "\n",
    "neg_text = []\n",
    "pos_text = []\n",
    "for file in neg_files:\n",
    "    text = get_text(file)\n",
    "    neg_text.append(text)\n",
    "for file in pos_files:\n",
    "    text = get_text(file)\n",
    "    pos_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the category of the word by using nltk method\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "tags = set(['NN', 'NNP', 'NNS', 'NNPS', 'VB', 'VBG', 'VBN', 'VBP', 'VBZ', 'RB', 'RBR', 'RBS', 'JJ', 'JJR', 'JJS'])\n",
    "def filter(text):\n",
    "    #using nltk to filter the stopword\n",
    "    wnl = WordNetLemmatizer()\n",
    "    sent = nltk.word_tokenize(text)\n",
    "#    print (sent)\n",
    "#    words = [LancasterStem.stem(w) for w in sent if w not in stopwords.words('english')]\n",
    "    words=[]\n",
    "    for w in sent: \n",
    "        if w not in stopwords.words('english'):\n",
    "            words.append(w)\n",
    "        \n",
    "    #words = [for w in sent if w not in stopwords.words('english')]\n",
    "    #print(words)\n",
    "#     get the categoyr of word\n",
    "    pos_tags =nltk.pos_tag(words)\n",
    "    ret = []\n",
    "    #filter\n",
    "    for word,pos in pos_tags:\n",
    "        \n",
    "        new = wnl.lemmatize(word)\n",
    "        \n",
    "        if (pos in tags):\n",
    "            ret.append(new)\n",
    "#    print(ret)\n",
    "    return ' '.join(ret)\n",
    "#     return ' '.join(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the text after filtering\n",
    "neg_txt = list(map(filter, neg_text))\n",
    "pos_txt = list(map(filter, pos_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    }
   ],
   "source": [
    "print(len(neg_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High cartoon comedy time program scho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness Houselessness George Carlin issue...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting Lesley Ann Warren Best d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>easily underrated film inn Brooks cannon Sure ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>typical Mel Brooks film much le slapstick movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n't comedic Robin Williams quirky/insane Robin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>art successfully make slow paced thriller. &lt; b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>critically acclaimed psychological thriller ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NIGHT LISTENER Robin Williams Toni Collette Bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>know Robin Williams God bless constantly shoot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High cartoon comedy time program scho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness Houselessness George Carlin issue...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting Lesley Ann Warren Best d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>easily underrated film inn Brooks cannon Sure ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>typical Mel Brooks film much le slapstick movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n't comedic Robin Williams quirky/insane Robin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>art successfully make slow paced thriller. &lt; b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>critically acclaimed psychological thriller ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NIGHT LISTENER Robin Williams Toni Collette Bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>know Robin Williams God bless constantly shoot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "# structer the data\n",
    "neg_pd = pd.DataFrame(columns = ['content', 'label'])\n",
    "pos_pd = pd.DataFrame(columns = ['content', 'label'])\n",
    "neg_pd['content'] = neg_txt\n",
    "neg_pd['label'] = np.ones((12500,1), dtype = np.int)\n",
    "pos_pd['content'] = pos_txt\n",
    "pos_pd['label'] = np.zeros((12500,1), dtype = np.int)\n",
    "data = pd.concat([pos_pd, neg_pd], axis = 0, ignore_index = True)\n",
    "display(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "count_vec = CountVectorizer()\n",
    "# cross validation\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.content, data.label, test_size=0.75, random_state=23)\n",
    "# word count by CountVectorizer\n",
    "x_train_mnb = count_vec.fit_transform(x_train)\n",
    "#print(x_train_mnb[0])  \n",
    "#print(\"happy\")\n",
    "x_test_mnb = count_vec.transform(x_test)\n",
    "#print(x_test_mnb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n\n          0       0.86      0.83      0.85      9367\n          1       0.84      0.87      0.85      9383\n\navg / total       0.85      0.85      0.85     18750\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "# calculate the tfidf of the text \n",
    "tfidf = TfidfTransformer()\n",
    "x_train_tf = tfidf.fit_transform(x_train_mnb)\n",
    "x_test_tf = tfidf.transform(x_test_mnb)\n",
    "#print(x_train_tf)\n",
    "#print(\"happy\")\n",
    "#print(x_test_tf)\n",
    "#predict by native bayes    \n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train_tf, y_train)\n",
    "print(classification_report(y_test, mnb.predict(x_test_tf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n\n          0       0.89      0.70      0.79      9367\n          1       0.76      0.91      0.83      9383\n\navg / total       0.82      0.81      0.81     18750\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm  \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#predict by SVM\n",
    "#dtc = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "\n",
    "model = svm.SVC(kernel='poly', degree=3, C=1.0)\n",
    "model.fit(x_train_mnb, y_train)\n",
    "print(classification_report(y_test, dtc.predict(x_test_mnb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n\n          0       0.80      0.86      0.83      9367\n          1       0.85      0.79      0.82      9383\n\navg / total       0.83      0.83      0.83     18750\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbdt=GradientBoostingClassifier(n_estimators=200) \n",
    "\n",
    "#predict by GBDT\n",
    "gbdt.fit(x_train_tf, y_train)\n",
    "print(classification_report(y_test, gbdt.predict(x_test_tf.toarray())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the perfomance of SVM is best, let's start predict\n",
    "count_vect = CountVectorizer()\n",
    "tf_idf = TfidfTransformer()\n",
    "X = data.content\n",
    "Y = data.label\n",
    "x_ct = count_vect.fit_transform(X)\n",
    "x_tf = tf_idf.fit_transform(x_ct)\n",
    "#svm = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "#svm.fit(x_tf, Y)\n",
    "mnb_pre = MultinomialNB()\n",
    "mnb_pre.fit(x_tf, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict_ct = count_vect.transform(x_predict)\n",
    "x_predict_tf = tf_idf.transform(x_predict_ct)\n",
    "predict = mnb_pre.predict(x_predict_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data['sentiment'] = predict\n",
    "predict_data.loc[predict_data.sentiment == 0, 'sentiment'] = 'negative'\n",
    "predict_data.loc[predict_data.sentiment == 1, 'sentiment'] = 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Desktop/sentiment/movie/0002.html</td>\n",
       "      <td>[Editor's note: Sites running 2.10 netnews wil...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Desktop/sentiment/movie/0003.html</td>\n",
       "      <td>Set in the offices of two psychoanalysts,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Desktop/sentiment/movie/0004.html</td>\n",
       "      <td>Starring: Mickey Rourke, Robert DeNiro, Lisa B...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Desktop/sentiment/movie/0005.html</td>\n",
       "      <td>Harry Angel (played by Mickey Rourke) is ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Desktop/sentiment/movie/0006.html</td>\n",
       "      <td>I've been a little lax in getting out mov...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Desktop/sentiment/movie/0002.html</td>\n",
       "      <td>[Editor's note: Sites running 2.10 netnews wil...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Desktop/sentiment/movie/0003.html</td>\n",
       "      <td>Set in the offices of two psychoanalysts,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Desktop/sentiment/movie/0004.html</td>\n",
       "      <td>Starring: Mickey Rourke, Robert DeNiro, Lisa B...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Desktop/sentiment/movie/0005.html</td>\n",
       "      <td>Harry Angel (played by Mickey Rourke) is ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Desktop/sentiment/movie/0006.html</td>\n",
       "      <td>I've been a little lax in getting out mov...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_data.to_csv('./Desktop/sentiment/result.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
